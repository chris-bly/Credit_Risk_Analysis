# Credit_Risk_Analysis
## Objective
The objective of this project was to evaluate the performance of multiple machine learning data models and their ability to predict credit risk based upon a real-world dataset of credit card credit. The evaluations of these data models will be compared to see if any are reasonable tools to help predict credit risk. This challenge utilized Python via Jupyter Notebook, as well as utilizing scikit-learn and imbalanced-learn libraries.
<br><br>
#### Predictive Models
---
The following machine learning models were utilized in this challenge:
- **RandomOversampler** and **SMOTE** oversampling algorithms
- **ClusterCentroids** undersampling algorithm
- **SMOTEENN** combination sampling algorithm
- **BalancedRandomForestClassifier** and **EasyEnsembleAdaBoostClassifier** ensemble classifier algorithms

## Results
**RandomOverSampler Model**<br>
<kbd>![RandomOverSampler](Resources/RandomOversampler.png)<kbd>
- The balanced accuracy score of the xxx model was xx.xx%
- The precision of the high_risk credit scores was xx.xx% and the high-risk recall was xx.xx%, leading to a F1 score of xx.xx%.
- The precision of the low_risk credit scores was xx.xx% and the low-risk recall was xx.xx%, leading to a F1 score of xx.xx%.<br><br>

**SMOTE Model**<br>
<kbd>![SMOTE](Resources/SMOTE.png)<kbd>
- The balanced accuracy score of the xxx model was xx.xx%
- The precision of the high_risk credit scores was xx.xx% and the high-risk recall was xx.xx%, leading to a F1 score of xx.xx%.
- The precision of the low_risk credit scores was xx.xx% and the low-risk recall was xx.xx%, leading to a F1 score of xx.xx%.<br><br>
 
**ClusterCentroids Undersampling Model**<br>
<kbd>![ClusterCentroids](Resources/ClusterCentroids.png)<kbd>
- The balanced accuracy score of the xxx model was xx.xx%
- The precision of the high_risk credit scores was xx.xx% and the high-risk recall was xx.xx%, leading to a F1 score of xx.xx%.
- The precision of the low_risk credit scores was xx.xx% and the low-risk recall was xx.xx%, leading to a F1 score of xx.xx%.<br><br>

**SMOTEENN Combination Sampling Model**<br>
<kbd>![SMOTEENN](Resources/SMOTEENN.png)<kbd>
- The balanced accuracy score of the xxx model was xx.xx%
- The precision of the high_risk credit scores was xx.xx% and the high-risk recall was xx.xx%, leading to a F1 score of xx.xx%.
- The precision of the low_risk credit scores was xx.xx% and the low-risk recall was xx.xx%, leading to a F1 score of xx.xx%.<br><br>

**BalancedRandomForestClassifier Model**<br>
<kbd>![BalancedRandomForestClassifier](Resources/RandomOversampler.png)<kbd>
- The balanced accuracy score of the xxx model was xx.xx%
- The precision of the high_risk credit scores was xx.xx% and the high-risk recall was xx.xx%, leading to a F1 score of xx.xx%.
- The precision of the low_risk credit scores was xx.xx% and the low-risk recall was xx.xx%, leading to a F1 score of xx.xx%.<br><br>
 
**EasyEnsembleAdaBoostClassifier Model**<br>
<kbd>![EasyEnsembleAdaBoostClassifier](Resources/EasyEnsembleClassifier.png)<kbd>
- The balanced accuracy score of the xxx model was xx.xx%
- The precision of the high_risk credit scores was xx.xx% and the high-risk recall was xx.xx%, leading to a F1 score of xx.xx%.
- The precision of the low_risk credit scores was xx.xx% and the low-risk recall was xx.xx%, leading to a F1 score of xx.xx%.<br><br>
 

## Conclusions

<kbd>![]()<kbd>
